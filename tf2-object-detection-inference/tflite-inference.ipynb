{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tflite infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "tflite_path = \"tflite/model.tflite\"\n",
    "image_path = \"65888.jpg\"\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get input shape\n",
    "input_shape = input_details[0]['shape']\n",
    "input_dtype = input_details[0]['dtype']\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, input_shape, input_dtype):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((input_shape[1], input_shape[2]))  # Resize to match model input\n",
    "    image = np.array(image, dtype=np.float32)\n",
    "\n",
    "    if input_dtype == np.uint8:  # If the model expects uint8 input\n",
    "        image = image.astype(np.uint8)\n",
    "    else:  # Normalize if model expects float32 input\n",
    "        image = image / 255.0\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = image_path  # Change this to your image path\n",
    "image = preprocess_image(image_path, input_shape, input_dtype)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], image)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Retrieve results\n",
    "scores = interpreter.get_tensor(output_details[0]['index'])  # Bounding boxes\n",
    "boxes = interpreter.get_tensor(output_details[1]['index'])  # Class IDs\n",
    "number_obj = interpreter.get_tensor(output_details[2]['index'])  # Confidence scores\n",
    "classes = interpreter.get_tensor(output_details[3]['index'])  # Confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80803525, 0.16386388, 0.10178218, 0.0799556 , 0.03316701,\n",
       "        0.02894149, 0.02824223, 0.0280828 , 0.02693336, 0.02679672]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 14:58:33.188231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 14:58:33.437964: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 14:58:34.526936: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2025-03-11 14:58:34.527049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:\n",
      "2025-03-11 14:58:34.527060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/mrkim/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrINS5_4core11RefCountPtrIS1_EEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# model_path = \"inference_graph/saved_model\"  # Update with your model path\n",
    "# model_path = \"inference_graph_resnet/saved_model\"  # Update with your model path\n",
    "# model_path = \"inference_graph_mbv2_640/saved_model\"  # Update with your model path\n",
    "model_path = \"tflite_mbv2_640/saved_model\"  # Update with your model path\n",
    "detect_fn = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_UserObject' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m input_tensor[tf\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[1;32m     16\u001b[0m num_detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_detections\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: '_UserObject' object is not callable"
     ]
    }
   ],
   "source": [
    "category_index = {1:'good', 2:'bad'}\n",
    "\n",
    "# Load and preprocess an image\n",
    "image_path = \"dataset/check/good2.jpeg\"\n",
    "image_np = cv2.imread(image_path)\n",
    "image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert image to tensor\n",
    "input_tensor = tf.convert_to_tensor(image_np)\n",
    "input_tensor = input_tensor[tf.newaxis, ...]  # Add batch dimension\n",
    "\n",
    "# Run inference\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# Extract results\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detection_boxes = detections['detection_boxes'][0].numpy()\n",
    "detection_classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "detection_scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "# Draw bounding boxes\n",
    "for i in range(num_detections):\n",
    "    if detection_scores[i] > 0.5:  # Confidence threshold\n",
    "        h, w, _ = image_np.shape\n",
    "        y_min, x_min, y_max, x_max = detection_boxes[i]\n",
    "        x_min, x_max, y_min, y_max = int(x_min * w), int(x_max * w), int(y_min * h), int(y_max * h)\n",
    "        cv2.rectangle(image_np, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        class_label = category_index.get(detection_classes[i], f\"Class {detection_classes[i]}\")\n",
    "        label = f\"{class_label}: {detection_scores[i]:.2f}\"\n",
    "        # text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2, 1)[0]\n",
    "        text_x, text_y = x_min, y_min - 5\n",
    "        cv2.putText(image_np, label, (text_x, text_y - 2), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(image_np)\n",
    "ax.axis('off')  # Optional: Hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_mbv2_640/model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get input shape\n",
    "input_shape = input_details[0]['shape']\n",
    "input_dtype = input_details[0]['dtype']\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, input_shape, input_dtype):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((input_shape[1], input_shape[2]))  # Resize to match model input\n",
    "    image = np.array(image, dtype=np.float32)\n",
    "\n",
    "    if input_dtype == np.uint8:  # If the model expects uint8 input\n",
    "        image = image.astype(np.uint8)\n",
    "    else:  # Normalize if model expects float32 input\n",
    "        image = image / 255.0\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"../dataset/check/good1.jpeg\"  # Change this to your image path\n",
    "image = preprocess_image(image_path, input_shape, input_dtype)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], image)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Retrieve results\n",
    "scores = interpreter.get_tensor(output_details[0]['index'])  # Bounding boxes\n",
    "boxes = interpreter.get_tensor(output_details[1]['index'])  # Class IDs\n",
    "number_obj = interpreter.get_tensor(output_details[2]['index'])  # Confidence scores\n",
    "classes = interpreter.get_tensor(output_details[3]['index'])  # Confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.37659684,  0.10950193,  0.744045  ,  0.85436153],\n",
       "        [ 0.02218023,  0.23012468,  0.64707184,  0.88190687],\n",
       "        [ 0.17242372,  0.32456216,  0.739125  ,  0.8860302 ],\n",
       "        [-0.17786482,  0.19046786,  0.7641169 ,  0.8094367 ],\n",
       "        [ 0.01500325,  0.26388648,  0.38661468,  0.90596604],\n",
       "        [-0.06196262,  0.07210046,  0.54124856,  0.93361264],\n",
       "        [ 0.39728656,  0.1060507 ,  1.13721   ,  0.8692758 ],\n",
       "        [ 0.08947109,  0.3016826 ,  0.49939537,  0.82053614],\n",
       "        [ 0.03304015,  0.10882419,  0.2325475 ,  0.58479095],\n",
       "        [ 0.10821638,  0.14258239,  0.72936976,  0.6595726 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 1., 1., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8504503 , 0.07880032, 0.03580749, 0.02587546, 0.02301262,\n",
       "        0.02105257, 0.02009058, 0.01984097, 0.01962679, 0.01928686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
